{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field - specifies torch how to handle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser', 'tagger'])\n",
    "\n",
    "\n",
    "all_stopwords = list(nlp.Defaults.stop_words)\n",
    "stop_punctuations = list(string.punctuation)\n",
    "\n",
    "all_stopwords.extend(stop_punctuations)\n",
    "all_stopwords.extend([\"/><br\", \"---\", \"...\", \"-pron-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def tokenizer(document):\n",
    "\n",
    "    import re\n",
    "    import string\n",
    "\n",
    "    doc = nlp(document)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "text_field = data.Field(sequential = True,\n",
    "                        tokenize = tokenizer, \n",
    "                        use_vocab=True, #Set to false for numeric\n",
    "                        lower=True,\n",
    "                        pad_token=None,\n",
    "                        unk_token='<unk>',\n",
    "                        stop_words=all_stopwords, \n",
    "                        batch_first = True\n",
    "                       )\n",
    "target_field = data.Field(sequential = False,\n",
    "                         use_vocab=False, # Set to false for numeric\n",
    "                         batch_first = True,\n",
    "                         dtype=torch.int64\n",
    "                         )\n",
    "\n",
    "\n",
    "#Specify how to handle each column in the data\n",
    "imdb_datafields = [(\"index\", None),\n",
    "                   (\"review\", text_field), \n",
    "                   (\"sentiment\", target_field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = data.TabularDataset.splits(path = \"data\",\n",
    "                                           train = \"imdb_reviews_train.csv\",\n",
    "                                           test = \"imdb_reviews_test.csv\",\n",
    "                                           format = \"csv\",\n",
    "                                           fields = imdb_datafields,\n",
    "                                           skip_header=True \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents in the Corpus:\n",
      "Train : 25000\n",
      " Test : 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Documents in the Corpus:\")\n",
    "print(\"Train : {}\".format(len(train_ds)))\n",
    "print(\" Test : {}\".format(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(train_ds, max_size = VOCAB_SIZE, min_freq = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing\n",
    "def make_bow_vector(batch, max_frequency_of_token):\n",
    "    \n",
    "    \n",
    "    reviews = [batch[idx].review for idx in range(MINI_BATCH_SIZE)]\n",
    "    sentiment = [int(batch[idx].sentiment) for idx in range(MINI_BATCH_SIZE)]\n",
    "    \n",
    "    vec = torch.zeros(MINI_BATCH_SIZE, VOCAB_SIZE+1)\n",
    "\n",
    "    for idx, review in enumerate(reviews):\n",
    "        for word in review:\n",
    "            vec[idx, text_field.vocab.stoi[word]] += 1\n",
    "    \n",
    "    # Clipping word frequency\n",
    "    vec = vec[:,1:].clamp(max= max_frequency_of_token)\n",
    "    # Scaling counts\n",
    "    vec/=max_frequency_of_token\n",
    "    return vec, torch.tensor(sentiment).reshape(-1,1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset=train_ds,\n",
    "                      batch_size = MINI_BATCH_SIZE,\n",
    "                      collate_fn = lambda batch : make_bow_vector(batch, \n",
    "                                                                  max_frequency_of_token=3)) \n",
    "                      # Passing Arguments to collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(dataset=test_ds,\n",
    "                      batch_size = MINI_BATCH_SIZE,\n",
    "                      collate_fn = lambda batch : make_bow_vector(batch, \n",
    "                                                                  max_frequency_of_token=3)) \n",
    "                      # Passing Arguments to collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_UNITS = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\tloss : 0.0010184933005086601\ttest loss : 0.001015266798951132\n",
      "epoch : 10\tloss : 0.001014237818510636\ttest loss : 0.0010110559061055292\n",
      "epoch : 20\tloss : 0.0010100032972252886\ttest loss : 0.0010068631538039888\n",
      "epoch : 30\tloss : 0.001005699872360815\ttest loss : 0.0010026537853738537\n",
      "epoch : 40\tloss : 0.0010014198472737656\ttest loss : 0.000998465987422582\n",
      "epoch : 50\tloss : 0.0009971632981849144\ttest loss : 0.0009942875646264352\n",
      "epoch : 60\tloss : 0.0009929204688352697\ttest loss : 0.0009901156205960246\n",
      "epoch : 70\tloss : 0.0009886831273813077\ttest loss : 0.000985934377631263\n",
      "epoch : 80\tloss : 0.0009844525695761755\ttest loss : 0.000981745665030711\n",
      "epoch : 90\tloss : 0.000980239237665825\ttest loss : 0.0009775623641050685\n",
      "epoch : 100\tloss : 0.0009760233142491802\ttest loss : 0.0009733753283615307\n"
     ]
    }
   ],
   "source": [
    "# 1. Model Architecture - Using Sequential\n",
    "model = nn.Sequential(nn.Linear(in_features = VOCAB_SIZE,\n",
    "                                out_features = HIDDEN_UNITS, bias=True),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(in_features = HIDDEN_UNITS,\n",
    "                                 out_features = 1),\n",
    "                       nn.Sigmoid()\n",
    "                       )\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# 3. Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    all_loss = 0\n",
    "    test_all_loss = 0\n",
    "    for batch_X, batch_y in train_dl:\n",
    "\n",
    "         # 1. Forward Propogation\n",
    "        y_pred = model(batch_X.float())\n",
    "        # 2. Compute Loss\n",
    "        loss = criterion(y_pred, batch_y.float())\n",
    "\n",
    "        # 3. Ensure gradients are all zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Back Propogate\n",
    "        loss.backward()\n",
    "\n",
    "        #5. Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_loss+=loss.item()\n",
    "        \n",
    "        break\n",
    "    \n",
    "    epoch_loss = all_loss/(len(train_dl))\n",
    "    if epoch%10 == 0:\n",
    "        print(\"epoch : {}\\tloss : {}\".format(epoch, epoch_loss), end = \"\\t\")\n",
    "    \n",
    "        model.eval()\n",
    "        for batch_X, batch_y in test_dl:\n",
    "            y_pred = model(batch_X.float())\n",
    "            test_loss = criterion(y_pred, batch_y.float())\n",
    "            test_all_loss+=test_loss.item()\n",
    "            break\n",
    "        test_epoch_loss = test_all_loss/len(test_dl)\n",
    "        print(\"test loss : {}\".format(test_epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   0, 116,  45,   0,   0,   0,   0, 497,   1,   0,   0,  56,  44,\n",
      "           0,   0,  11,   0,   0,   6,   0,   0,   7,   0,   0,   0,   0, 376,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0],\n",
      "        [  0,  73,   1, 488,   0, 145, 498,   0,   0,  87, 108,   0,   0,  72,\n",
      "         439,   0,   0,   0,   0,   0, 321, 190,   0,   0,   0, 412,  11,   0,\n",
      "           0,   3,   0,   0,  96, 244,   0,   0, 458,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,  25,  61,   0,   0, 182,   0,   0,   0,\n",
      "           0,   0, 201,   0,   0,   0,   0,   0,  45,   0,   0,  13, 117,   0,\n",
      "         376,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0, 443, 127,   3,  41, 315,   0,   0,   0,   0,  16,   0,\n",
      "           0]]) tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Iterator\n",
    "train_dl, test_dl = Iterator.splits(datasets = (train_ds, test_ds),\n",
    "                                    batch_sizes = (2, 2),\n",
    "                                    shuffle = False,\n",
    "                                    sort_within_batch = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
