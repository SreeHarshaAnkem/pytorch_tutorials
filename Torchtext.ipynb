{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c pytorch torchtext --y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "1. Internal \n",
    "2. External"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser', 'tagger'])\n",
    "\n",
    "\n",
    "all_stopwords = list(nlp.Defaults.stop_words)\n",
    "stop_punctuations = list(string.punctuation)\n",
    "\n",
    "all_stopwords.extend(stop_punctuations)\n",
    "all_stopwords.extend([\"/><br\", \"---\", \"...\", \"-pron-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(document, print_n=1000, label=None):\n",
    "\n",
    "    import re\n",
    "    import string\n",
    "\n",
    "    doc = nlp(document)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify how to handle each column in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "text_field = data.Field(sequential = True,\n",
    "                        tokenize = tokenizer, \n",
    "                        use_vocab=True, #Set to false for numeric\n",
    "                        lower=True,\n",
    "                        stop_words=all_stopwords, \n",
    "                        batch_first = True\n",
    "                       )\n",
    "target_field = data.Field(sequential = False,\n",
    "                         use_vocab=False, # Set to false for numeric\n",
    "                        batch_first = True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading an external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "#Specify how to handle each column in the data\n",
    "imdb_datafields = [(\"index\", None),\n",
    "                   (\"review\", text_field), \n",
    "                   (\"sentiment\", target_field)]\n",
    "\n",
    "# Loading starts here\n",
    "train_ds = TabularDataset(path = \"data/imdb_reviews_train.csv\",\n",
    "                           format = \"csv\",\n",
    "                           fields = imdb_datafields,\n",
    "                           skip_header=True # True if the file has header\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be accessed using index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Review : ['movie', 'respect', 'sure', 'lot', 'memorable', 'quote', 'list', 'gem', 'imagine', 'movie']\n",
      "Sentiment : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"   Review : {}\".format(train_ds[0].review[0:10]))\n",
    "print(\"Sentiment : {}\".format(train_ds[0].sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train and Test Files in a single go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = TabularDataset.splits(path = \"data\",\n",
    "                       train = \"imdb_reviews_train.csv\",\n",
    "                       test = \"imdb_reviews_test.csv\",\n",
    "                       format = \"csv\",\n",
    "                       fields = imdb_datafields,\n",
    "                       skip_header=True \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents in the Corpus:\n",
      "Train : 25000\n",
      " Test : 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Documents in the Corpus:\")\n",
    "print(\"Train : {}\".format(len(train_ds)))\n",
    "print(\" Test : {}\".format(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge spacy  --y\n",
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "1. Building only based on train data.\n",
    "2. Creates index for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(train_ds,max_size = 500, min_freq = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 50366),\n",
       " ('film', 47007),\n",
       " ('good', 23827),\n",
       " ('like', 22170),\n",
       " ('time', 15559),\n",
       " ('character', 13852),\n",
       " ('watch', 13413),\n",
       " ('story', 12848),\n",
       " ('think', 12199),\n",
       " ('little', 11409),\n",
       " ('scene', 10330),\n",
       " ('look', 9841),\n",
       " ('great', 9835),\n",
       " ('know', 9310),\n",
       " ('people', 9222),\n",
       " ('end', 9182),\n",
       " ('bad', 9119),\n",
       " ('way', 8592),\n",
       " ('play', 8533),\n",
       " ('act', 8452)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.freqs.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of each token in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie</td>\n",
       "      <td>50366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respect</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sure</td>\n",
       "      <td>2621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lot</td>\n",
       "      <td>4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memorable</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  frequency\n",
       "0      movie      50366\n",
       "1    respect        640\n",
       "2       sure       2621\n",
       "3        lot       4619\n",
       "4  memorable        649"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_token_count = pd.DataFrame.from_dict(text_field.vocab.freqs, \n",
    "                                        orient=\"index\").reset_index()\n",
    "df_token_count.columns = [\"token\", \"frequency\"]\n",
    "df_token_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>character</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>watch</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>story</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  idx\n",
       "0      <unk>    0\n",
       "1      <pad>    1\n",
       "2      movie    2\n",
       "3       film    3\n",
       "4       good    4\n",
       "5       like    5\n",
       "6       time    6\n",
       "7  character    7\n",
       "8      watch    8\n",
       "9      story    9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_token_idx = pd.DataFrame.from_dict(text_field.vocab.stoi, \n",
    "                                        orient=\"index\").reset_index()\n",
    "df_token_idx.columns = [\"token\", \"idx\"]\n",
    "df_token_idx.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create mini batches for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator\n",
    "\n",
    "Equivalent to DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = Iterator.splits(datasets = (train_ds, test_ds),\n",
    "                batch_sizes = (2, 2))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie',\n",
       " 'respect',\n",
       " 'sure',\n",
       " 'lot',\n",
       " 'memorable',\n",
       " 'quote',\n",
       " 'list',\n",
       " 'gem',\n",
       " 'imagine',\n",
       " 'movie',\n",
       " 'joe',\n",
       " 'piscopo',\n",
       " 'actually',\n",
       " 'funny',\n",
       " 'maureen',\n",
       " 'stapleton',\n",
       " 'scene',\n",
       " 'stealer',\n",
       " 'moroni',\n",
       " 'character',\n",
       " 'absolute',\n",
       " 'scream',\n",
       " 'watch',\n",
       " 'alan',\n",
       " 'skipper',\n",
       " 'hale',\n",
       " 'jr',\n",
       " 'police',\n",
       " 'sgt']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  5, 117,   0,   0,   0,   0, 130,   2,   0,   0,   0,   0,   0,   0,\n",
      "         347,   0,   3,   0,   0,   0,   0,   0, 276,   0, 488,   0,   0,   0,\n",
      "           0,   0,  37,   0,   0, 235,   0, 191,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0, 200,   0,   0,  94,   0, 425,  17, 131,  55,   0,   0, 132,\n",
      "          69,   0,  41,   0,   0,   2,   0,   0,   0,   0,   2,   0,   0, 353,\n",
      "           0,  55,  55,   9,   0,  82, 100,  82,   6,   6,   0, 166,   0,   0,\n",
      "           0,   0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [102,   0,  78,   0,   0,   0,   0,   0, 245, 262,   0,   0,   0,   0,\n",
      "           0, 219, 103,   0,   0, 119,   0, 199,   0,   0,   0,   0, 319,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 482,   0,  82,  66,\n",
      "           0,   0, 181,   0,   0,   0, 240,  38,   0,  95,  16,   0, 240,   0,\n",
      "          26,   0,   0,   0,   0, 339, 240,   0,  26, 313,   0, 122,   0,  66,\n",
      "          82, 178,   0,   0,   0,   0, 488, 313,   0, 482,   0,   0,   0,   0,\n",
      "         236,   0,  33, 181,   0,   0, 414,   0,   0,   0, 199,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 313,   0,\n",
      "           0,   0,   0,   0,   0, 219,   0,  37, 219, 103,   0, 199,   0,   0,\n",
      "           0,   0,  61,   0,   3,   0,   0,   0,   0,  60,   0, 236,   5,   3,\n",
      "           0,  38, 361,  60,   0,   0,  38,   0,   0,   0,   0,   0,   0,   0,\n",
      "         317, 406, 161,   0,   0, 390,   3,  64, 388,   0, 406,   0,   3,   0,\n",
      "          11]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(batch.review, batch.sentiment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "\n",
    "# - chapter TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket Iterator \n",
    "\n",
    "# - LSTM chapter\n",
    "# - valid for sequence data - groups sequences of similar length together for \n",
    "# computational efficiency while padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPTT Iterator\n",
    "# - Language Model chapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
